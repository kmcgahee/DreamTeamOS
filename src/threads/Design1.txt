
CIS 520 - Programming Project #1

                   
---- GROUP ----

Kyle  McGahee  kmcgahee@ksu.edu
Matt  Roselli  mroselli@ksu.edu
Jacob Kongs    jmkongs@ksu.edu

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for
>> the TA, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation,
>> course text, lecture notes, and course staff.


                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less

PURPOSE: Wraps all information and semaphore needed to implement efficient thread sleeping.
struct sleep_context
{
    struct semaphore sema;   /* Semaphore used for blocking sleeping thread. */
    int64_t start_ticks;     /* Ticks at start of sleep command. */
    int64_t sleep_ticks;     /* Number of ticks to sleep. */
    struct list_elem elem;   /* List element for context of sleeping threads. */
};

PURPOSE: Allow threads to track information on a 'per-thread' basis to eliminate multiple sleep race conditions.
struct thread
{
    ...
    ...
    struct sleep_context sleep_info;    /* Sleeping context information */
    ...
};


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to your timer_sleep(),
>> including the effects of the timer interrupt handler.

The timer_sleep() method does a some sanity checks and then calls off to 
thread_sleep() which stores sleeping information and adds thread sleeping
context to a list and then blocks the thread with the sema_down() function.
When the timer tick ISR fires it checks through the list of sleeping threads 
and if the correct number of ticks has elapsed then the thread is woken up 
with the sema_up() function.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The sleeping threads are tracked in their own list, thus eliminating the need
to iterate through every thread and check if it is asleep and then if it needs
to be woken up.  This scales much better to a large system with many threads.


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Each thread tracks implements self-blocking with its own independently
owned semaphore.  This means that multiple threads can call timer_sleep()
without affecting the semaphore and times of other threads.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Interrupts are temporarily disabled before calling thread_sleep().
This ensures that a data race condition cannot occur when the start 
and end ticks are being stored and between adding the sleep context
to the list and calling sema_down().  

At the completion of timer_sleep() the interrupt status is returned
to what is was before the function was called.


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> other designs that you considered?

Other design choices that were considered were placing all sleep specific 
information directly in the struct itself and adding a flag into each 
thread marking whether or not the sleep info was valid, then iterating
through all threads in the ISR and checking the flag.  The reason the 
implemented design was chosen is listed below.

The design was chosen because it accomplished two goals...

1) It logically wrapped all information relating to sleeping into a struct
   to keep from littering the thread struct with multiple field related field
   definitions.  It also allows for easier to read code when de-referencing 
   the sleep info data as the field name is then explicitly stated in the code.
   
2) Creating a new list for tracking sleeping threads allows for a more elegant
   solution than brute-force iterating through every thread and checking a flag
   if the thread is asleep or not.  It also eliminates the need for 
   the 'sleeping' flag mentioned above because the act of being in the list 
   denotes that the thread is currently sleeping.


             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

PURPOSE: Save original priority and keep references to locks of interest when doing priority donation.
struct thread
{
    ...
    ...
    int org_priority;                   /* Original priority level. */
    ...
    struct list owned_locks;            /* List of locks owned by this thread. */
    struct lock * blocking_lock;        /* Lock that is blocking this thread. */
    ...
};

PURPOSE: Corresponding list element to allowed locks to be stored in 'owned' locks list mentioned above.
struct lock 
  {
    ...
    struct list_elem elem;      /* List element for tracking owned locks */
  };

>> B2: Explain the data structure used to track priority donation.

The already existing 'thread' data structure was used to track priority donation.
An extra priority level is now stored in this data structure to 'remember' the steady state prioirity
of the thread.

In addition the 'thread' structure now contains a list structure containing elements of the 'lock' data type
as well as a reference to what lock is currently blocking that thread (or NULL if the thread isn't blocked).
By allowing threads to know about which threads they currently own they can make correct decisions when releasing a lock.
By knowing the currently blocking thread the OS can propogate priorities in nested lock situations.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

The list of threads containing blocked or waiting threads are always kept descendingly sorted by effective priority level.
This invariant allows the scheduler/primitive to grab the first thread in the list.  This also has the desirable effect
that when multiple threads have the same priority they can be scheduled in a cyclic order.  

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

First the calling thread tries to grab the lock by calling sema_try_down().
Assuming another thread already owns the lock it will then call thread_donate_priority() 
in order to recursively propogate its priority down to the lock owner and if that thread is 
blocked then propogate the priority to the owner of that lock. This propogation will continue
until either a thread isn't blocked by a lock or a thread has a greater than or equal to priority
compared to the priority being donated.

Once the priority of the calling thread has been correctly donated to other threads the sema_down()
function is called for the locks semaphore which will always block the calling thread and add it to
the lock's waitlist.

Finally the calling thread stores the lock in it's 'currently owned' list and sets the lock's owner reference to itself.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

First the lock will be removed from the 'owned locks list' associated with the owner of the lock since the lock
is about to have a new owner.

Then the lock's current owner will iterate through all of its 'owned locks' and find the maximum priority thread
that still is waiting on the owner thread.  The lock's current owner will then either restore its effective priority
to its original priority or the max priority found in the iteration above if it greater than the original priority.

Finally the locks owner will be cleared and sema_up() will be called on the lock's semaphore to schedule the next
highest priority thread if one is waiting. 

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

The potential race condition exists if thread_set_priority is interrupted between setting the current thread's 
priority to the new priority and resetting the org_priority to the new priority. To avoid this race condition 
interrupts are disabled before resetting any priority values and restored before calling thread_yield. In this 
case a lock could not be utilized because we are not concerned about another thread using the resource. Our only 
concern is the interruption of this procedure.  

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

One reason this design was chosen because it allowed the already existing 'priority' field of the
thread structure to be the effective priority of the thread. We had considered storing relative donations
but then code already using the 'priority' field would have to be updated to use some 'thread_effective_priority()'
function or macro that computed the effective priority.

We had also considered storing references to the thread of the lock that was blocking another thread, but instead we 
chose to keep a reference to the blocking lock.  This is superior because the lock already contains a reference to the
owner thread and also encapsulates other threads waiting on the lock through the use of a semaphore.  This extra information
allows our design to correctly set the effective priority of a thread when it releases a lock as mentioned in section B5 above.  

              ADVANCED SCHEDULER [EXTRA CREDIT]
              =================================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

